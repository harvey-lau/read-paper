# The Extensive Reading of 2022-[*AI/ML for Network Security: The Emperor has no Clothes*](https://dl.acm.org/doi/10.1145/3548606.3560609)

- The **problem** is that synthesizing such explainable models that capture a given black-box model's decisions with high fidelity while also being practical (i.e., small enough in size for humans to comprehend) is challenging.
- The **solution** is Trustee, a framework that takes **an existing ML model and training dataset** as input and generates **a high-fidelity, easy-to-interpret decision tree and associated trust report** as output.

We can understand Trustee as a specification generator for black-box ML model.

The main steps of Trustee are (refer to Algorithm 1 for more details):

1. Extracting decision trees.
2. Processing decision trees.
   1. Pruning decision trees.
   2. Generating Trust Reports.

The key element of Trustee is DT.

The 4 requirements of DT are:

- **Model-agnostic**: applicable to any given black-box model.
- **High-fidelity**: the predictive performance of DTs is similar to the black-box model.
- **Low-complexity**: selected parts of the DTs are intelligible and easy to understand by domain experts.
- **Stability**: the final DT's decisions should be insensitive to the minute details of how this final DT explanation has been determined.

How to exploit the extracted DT explanation for the purpose of enabling a user to investigate the black-box model for likely indications of the presence of inductive biases.

The 3 instances of inductive biases:

- **Shortcut learning**: shortcuts are decision rules that perform well on standard benchmarks but fail to transfer to more challenging testing conditions, such as read-world scenarios.
- **Spurious correlations**: a spurious correlation is a mathematical relationship in which two or more events or variables are associated but not causally related, due to either coincidence or the presence of a certain third, unseen factor.
- **Out-of-distribution samples**: the closed-world approach to deep learning operates using the assumption that both training and test data are drawn from the same application-specific distribution `P`. However, in a real-world environment, ML systems need to be resilient to data at test time that is not drawn from P but belongs to the same input space, i.e. they encounter samples that are out-of-distribution (OOD).

Using Trustee in practice:

1. Getting started: select the ML model and the dataset.
2. Selecting hyper-parameters: select values for 4 hyper-parameters like the `k` of Top-`k` Pruning method.
3. Detecting under-specification issues.
4. Validating DT explanations.
